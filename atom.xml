<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Liu Sida's Homepage</title>
 <link href="http://liusida.com/atom.xml" rel="self"/>
 <link href="http://liusida.com/"/>
 <updated>2016-10-30T22:11:54+08:00</updated>
 <id>http://liusida.com</id>
 <author>
   <name>liusida</name>
   <email></email>
 </author>

 
 <entry>
   <title>Thank you, GitHub and Jekyll</title>
   <link href="http://liusida.com/2016/10/30/thank-you-github-n-jekyll/"/>
   <updated>2016-10-30T00:00:00+08:00</updated>
   <id>http://liusida.com/2016/10/30/thank-you-github-n-jekyll</id>
   <content type="html">&lt;p&gt;Thank you, GitHub and Jekyll.&lt;/p&gt;

&lt;p&gt;Now I have my homepage again.&lt;/p&gt;

&lt;p&gt;I'd like to share my &lt;em&gt;thoughts&lt;/em&gt; and &lt;em&gt;ideas&lt;/em&gt; and &lt;em&gt;source codes&lt;/em&gt; here. Hope they helped.&lt;/p&gt;

&lt;p&gt;btw, I am so happy to see Jekyll's way of managing a website. It reminds me of the old days.&lt;/p&gt;

&lt;p&gt;Here is my naive thoughts back in 2007 (Oh my god, it was almost 10 years ago!):&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I found a very interesting method of templates when I was writing a website yesterday.&lt;/p&gt;

&lt;p&gt;Normal template technology is using PHP programs to read a template file, and parsing the symbols itself, than get the final &gt; version of PHP page codes, store those to a work cache folder, and show that if need.&lt;/p&gt;

&lt;p&gt;The popular technology of template in PHP is like Smarty or sth.&lt;/p&gt;

&lt;p&gt;I got another way to using template. Anyway, it may be not so securable, but it's very easy to use.&lt;/p&gt;

&lt;p&gt;1, Make HTML pages, and give them PHP extension name.
Like: template.php&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;php&quot;&gt;&amp;lt;html&amp;gt; 
&amp;lt;body&amp;gt; 
hello, world. 
&amp;lt;/body&amp;gt; 
&amp;lt;/html&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2, Create different pages which really need to show.
Like: page.php&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;php&quot;&gt;&amp;lt;? 
  $str = hello, world. 
  include('template.php'); 
?&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Replace the string using the PHP vars.
Like: template.php&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code class=&quot;php&quot;&gt;&amp;lt;html&amp;gt; 
&amp;lt;body&amp;gt; 
&amp;lt;?=$str?&amp;gt; 
&amp;lt;/body&amp;gt; 
&amp;lt;/html&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ok, call page.php, you can see your work.&lt;/p&gt;

&lt;p&gt;Addtional, you can even give the template.php a List to show the records. That's a great thing.&lt;/p&gt;&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>About sparse_column_with_hash_bucket</title>
   <link href="http://liusida.com/2016/10/30/hash-bucket/"/>
   <updated>2016-10-30T00:00:00+08:00</updated>
   <id>http://liusida.com/2016/10/30/hash-bucket</id>
   <content type="html">&lt;p&gt;Yesterday, I saw tf.contrib.layers.sparse_column_with_hash_bucket in a &lt;a href=&quot;https://www.tensorflow.org/versions/r0.11/tutorials/wide/index.html&quot;&gt;tutorial&lt;/a&gt;. That's a very useful function! I thought. I never met such a function in Keras or TFLearn.&lt;/p&gt;

&lt;p&gt;Basically, the function do something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;hash(category_string) % dim
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let's say the text &quot;the quick brown fox&quot;. If we want to put them into 5 buckets, we can get result like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;hash(the) % 5 = 0
hash(quick) % 5 = 1
hash(brown) % 5 = 1
hash(fox) % 5 = 3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This example is metioned by &lt;a href=&quot;https://www.quora.com/Can-you-explain-feature-hashing-in-an-easily-understandable-way&quot;&gt;Luis Argerich&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That's really easy for preprocessing, but there are disadvantages of that, metioned by &lt;a href=&quot;https://www.quora.com/Can-you-explain-feature-hashing-in-an-easily-understandable-way&quot;&gt;Artem Onuchin&lt;/a&gt; also in that page.&lt;/p&gt;

&lt;p&gt;So, the common way to do this &lt;strong&gt;feature engineering&lt;/strong&gt; thing is metioned by &lt;a href=&quot;https://www.quora.com/What-are-some-best-practices-in-Feature-Engineering&quot;&gt;Rahul Agarwal&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Scaling by Max-Min&lt;/li&gt;
&lt;li&gt;Normalization using Standard Deviation&lt;/li&gt;
&lt;li&gt;Log based feature/Target: use log based features or log based target function.&lt;/li&gt;
&lt;li&gt;One Hot Encoding&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Anyway, if we want to do hash_bucket without tensorflow, we can do it in Pandas which is metioned &lt;a href=&quot;http://stackoverflow.com/questions/8673035/what-is-feature-hashing-hashing-trick/33581487&quot;&gt;here&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;import pandas as pd
import numpy as np

data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],
        'year': [2000, 2001, 2002, 2001, 2002],
        'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}

data = pd.DataFrame(data)

def hash_col(df, col, N):
    cols = [col + &quot;_&quot; + str(i) for i in range(N)]
    print(cols)
    def xform(x): tmp = [0 for i in range(N)]; tmp[hash(x) % N] = 1; return pd.Series(tmp,index=cols)
    df[cols] = df[col].apply(xform)
    return df.drop(col,axis=1)

print(hash_col(data, 'state',4))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;result:
&lt;code&gt;code
   pop  year  state_0  state_1  state_2  state_3
0  1.5  2000        1        0        0        0
1  1.7  2001        1        0        0        0
2  3.6  2002        1        0        0        0
3  2.4  2001        1        0        0        0
4  2.9  2002        1        0        0        0
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Edited]&lt;/strong&gt; Actually, we can use &lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html&quot;&gt;pandas.get_dummies&lt;/a&gt; to do this directly:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;import pandas as pd

data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],
        'year': [2000, 2001, 2002, 2001, 2002],
        'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}

data = pd.DataFrame(data)
print(pd.get_dummies(data, columns=['state','year']))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;result:
&lt;code&gt;code
   pop  state_Nevada  state_Ohio  year_2000  year_2001  year_2002
0  1.5           0.0         1.0        1.0        0.0        0.0
1  1.7           0.0         1.0        0.0        1.0        0.0
2  3.6           0.0         1.0        0.0        0.0        1.0
3  2.4           1.0         0.0        0.0        1.0        0.0
4  2.9           1.0         0.0        0.0        0.0        1.0
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After all,&lt;/p&gt;

&lt;p&gt;I think I should learn more about one-hot-encoding and word2vec embedding.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Coming up with features is difficult, time-consuming, requires expert knowledge. &quot;Applied machine learning&quot; is basically feature engineering.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Said &lt;a href=&quot;http://www.andrewng.org/&quot;&gt;Andrew Ng&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 

</feed>
