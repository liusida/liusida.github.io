<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    
    Liu Sida’s Homepage
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/font.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.png">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>


  <body>

    <header class="masthead">
          <p>
            <a href='https://github.com/liusida/'>
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#333" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            </a>
          </p>
      <div class="masthead-inner">
        <h1><a href='/' id='site-title'>Liu Sida's Homepage</a></h1>
        <p class="lead">Machine Learning & Human Learning</p>

        <div class="colophon">
          <p>&copy; 2014. liusida All rights reserved.</p>
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1>
      <a href="/2018/06/27/what-is-mathematics/">
        What is Mathematics According to Keith Devlin
      </a>
    </h1>

    <span class="post-date">27 Jun 2018</span>

    In Keith Devlin’s book ‘Introduction to Mathematical Thinking’, he writes,<br><br>

“Virtually nothing (with just two further advances, both from the 17th century: calculus and probability theory) fr...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2018/05/29/dynamic-nn/">
        Dynamic NN Allowing Additional Evidence?
      </a>
    </h1>

    <span class="post-date">29 May 2018</span>

    We have traditional Neural Network (NN), with static structure like this:<br><br>

signal -&gt; input -&gt; hidden layer -&gt; prediction =?= truth<br><br>

-&gt;  means to propagate forward
=?= means ...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2017/09/27/highest-IQ/">
        Why does the person with highest IQ not become the most successful one?
      </a>
    </h1>

    <span class="post-date">27 Sep 2017</span>

    I heard about the “Study of Mathematically Precocious Youth After 35 Years” years ago, but after studying machine learning, especially the generalization problem, I guess I have glanced some possib...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2017/09/24/use-tensorflow-to-compute-gradient/">
        Use Tensorflow to Compute Gradient
      </a>
    </h1>

    <span class="post-date">24 Sep 2017</span>

    In most of Tensorflow tutorials, we use minimize(loss) to automatically update parameters of the model.<br><br>

In fact, minimize() is an integration of two steps: computing gradients, and applying ...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2017/09/23/scree-of-pca/">
        Scree of PCA(Principal Component Analysis)
      </a>
    </h1>

    <span class="post-date">23 Sep 2017</span>

    I learned the concept of PCA today, and found out this method of reducing dimension is quite terse.<br><br>

If we do PCA to a 40-d dataset, reduce it into a 2-d dataset, it simply choose the 2 most ...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2017/09/09/learning-rate-too-large/">
        Learning Rate is Too Large
      </a>
    </h1>

    <span class="post-date">09 Sep 2017</span>

    What if I see a training accuracy scalar graphic like this:<br><br>

<br><br>

The accuracy curve of training mini-batch is going down a little bit over time after reached a relative high point. That m...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2017/09/08/manipulating-tensorboard/">
        Manipulating Tensorboard
      </a>
    </h1>

    <span class="post-date">08 Sep 2017</span>

    Tensorboard is a very useful tool for visualizing the logs of Tensorflow. It is now an independent project on GitHub, here’s the link.<br><br>

In the past, if we were doing small projects, we usuall...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2017/08/24/deep-scratch/">
        Implement a Deep Neural Network using Python and Numpy
      </a>
    </h1>

    <span class="post-date">24 Aug 2017</span>

    I have just finished Andrew Ng’s new Coursera courses of Deep Learning (1-3). They are one part of his new project DeepLearning.ai.<br><br>

In those courses, there is a series of interview of Heroes...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/11/25/cross-entropy/">
        Cross Entropy 的通俗意义
      </a>
    </h1>

    <span class="post-date">25 Nov 2016</span>

    cross_entropy 公式如下：<br><br>



它描述的是可能性 S 到 L 的距离，也可以说是描述用 S 来描述 L 还需要多少信息（如果是以2为底的log，则代表还需要多少bit的信息；如果是以10为底的log，则代表还需要多少位十进制数的信息）。<br><br>

当年 香农 Shannon 创立信息论的时候，考虑的是每一次都是扔硬币，结果只有2个可能，所以用的是以2为底，发明了...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/11/24/deriving-lstm/">
        推荐《写下记忆：理解、推导、扩展LSTM》
      </a>
    </h1>

    <span class="post-date">24 Nov 2016</span>

    今天学习一篇挺有意思的文章《写下记忆：理解、推导、扩展LSTM》（英文），从 RNN 的原理开始讲起，并讲述 RNN 为什么理论上很美好，实践起来要出问题，以及各种问题是怎么被解决的，从而诞生了 LSTM 。<br><br>

不过似乎作者隐藏了他的私人信息，不知道是谁，本来还想看看是哪国人，因为感觉不是英语母语。:P<br><br>

这回应该不会忘记为什么 Basic LSTM 的模型是那样的了...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/11/16/study-lstm/">
        学习Tensorflow的LSTM的RNN例子
      </a>
    </h1>

    <span class="post-date">16 Nov 2016</span>

    前几天写了学习Embeddings的例子，因为琢磨了各个细节，自己也觉得受益匪浅。于是，开始写下一个LSTM的教程吧。<br><br>

还是Udacity上那个课程。<br><br>

源码也在Github上。<br><br>

RNN是一个非常棒的技术，可能它已经向我们揭示了“活”的意义。RNN我已经尝试学习了几次，包括前面我这篇笔记，所以就直接进入代码阅读吧。<br><br>

读例子程序：

1. ...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/11/14/study-embeddings/">
        学习Tensorflow的Embeddings例子
      </a>
    </h1>

    <span class="post-date">14 Nov 2016</span>

    Udacity 上有一个 Google 技术人员提供的基于 Tensorflow 的深度学习课程，今天学到 Embeddings ，有点难理解，所以写个笔记记录下，以备日后回忆。<br><br>

链接：<br><br>

Udacity课程视频 这个课程在 Udacity 上的难度级别已经是 高 了。估计再下去就更少视频学习内容了。:~(<br><br>

例子Github地址<br><br>

理解课程...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/11/12/how-to-ask-a-good-question/">
        如何问一个好问题？
      </a>
    </h1>

    <span class="post-date">12 Nov 2016</span>

    本文翻译自StackOverflow.com，原文链接（英文）<br><br>

首先，我们很愿意帮助你。为了提高你获得回答的机会，这里有几个小提示：<br><br>

先搜索，再搜索。

把你找到的东西记下来。就算你在搜索的时候找不到其他有用的答案，把你搜到的跟你问题有关的链接放进来并说明为什么没有回答你的问题，这样能够让来回答的人更明白你问题的意思。<br><br>

写一个能够准确概括你问题的标题...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/11/04/rnn-implementation/">
        Recurrent Neural Network(RNN) Implementation
      </a>
    </h1>

    <span class="post-date">04 Nov 2016</span>

    I heard about RNN for a long time, and have learned the concept several times, but until yesterday, I can’t implement any useful code to solve my own problem.<br><br>

So I checked some tutorial. The...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/10/31/translate-from-tf-2-keras/">
        from Tensorflow to Keras
      </a>
    </h1>

    <span class="post-date">31 Oct 2016</span>

    I know 3 high level api for deep learning. They are Tensorflow.contrib.learn(SKFlow), TFLearn and Keras. All of them are great tools, but maybe I like Keras because of the easy style of code.<br><br>...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/10/30/hash-bucket/">
        About sparse_column_with_hash_bucket
      </a>
    </h1>

    <span class="post-date">30 Oct 2016</span>

    Yesterday, I saw tf.contrib.layers.sparse_column_with_hash_bucket in a tutorial. That’s a very useful function! I thought. I never met such a function in Keras or TFLearn.<br><br>

Basically, the fun...
  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/10/29/thank-you-github-n-jekyll/">
        Thank you, GitHub and Jekyll
      </a>
    </h1>

    <span class="post-date">29 Oct 2016</span>

    Thank you, GitHub and Jekyll.<br><br>

Now I have my homepage again.<br><br>

I’d like to share my thoughts and ideas and source codes here. Hope they helped.<br><br>

btw, I am so happy to see Jekyll’s ...
  </div>
  
</div>

<!-- Pagination links -->
<div class="pagination">
  
    <span class="next">Older</span>
  
  
    <span class="previous">Newer</span>
  
</div>

    </div>

  </body>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-105744782-1', 'auto');
  ga('send', 'pageview');

</script>  
</html>
