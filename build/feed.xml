<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="http://172.25.168.122:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://172.25.168.122:4000/" rel="alternate" type="text/html" /><updated>2023-06-02T11:04:21+08:00</updated><id>http://172.25.168.122:4000/feed.xml</id><title type="html">Sida Liu</title><subtitle>The world is so complex that we cannot stop learning.</subtitle><author><name>Sida Liu</name></author><entry><title type="html">A Plan to Make an AI Programmer</title><link href="http://172.25.168.122:4000/ai/2023/06/02/ai-programmer/" rel="alternate" type="text/html" title="A Plan to Make an AI Programmer" /><published>2023-06-02T00:00:00+08:00</published><updated>2023-06-02T00:00:00+08:00</updated><id>http://172.25.168.122:4000/ai/2023/06/02/ai-programmer</id><content type="html" xml:base="http://172.25.168.122:4000/ai/2023/06/02/ai-programmer/">&lt;p&gt;What are the required skills for a being to be a programmer?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Coding: they must be capable of writing code, surely. This is a token-level ability.&lt;/li&gt;
  &lt;li&gt;Project management: project management skills are also important, which may involve organizing files into a structure that is easy to navigate later.&lt;/li&gt;
  &lt;li&gt;Documentation: the ability to produce documentation that clearly explains project ideas is also needed.&lt;/li&gt;
  &lt;li&gt;Testing: regularly testing can maintain code quality.&lt;/li&gt;
  &lt;li&gt;Collaboration: programmers should also be able to collaborate with other programmers, adjusting and progressing when others modify their code.&lt;/li&gt;
  &lt;li&gt;Philosophy: programmers should be creative, wise and kind-hearted, with goals that align with ethical standards.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Current GPT models (3.5 or 4) serve as a good starting point for all these requirements above, especially 3 and 6, since it doesn‚Äôt just read code but also tons of books, it must be wiser than single-minded coding machines. However, since its model weights are not publicly available, the first step is to create or find an alternative to GPT.&lt;/p&gt;

&lt;p&gt;Next, we need a Reinforcement Learning environment. Similar to training a human programmer, we must design a curriculum for AI to help it develop its programming skills. The curriculum will start with the classic ‚Äúhello, world!‚Äù task.&lt;/p&gt;

&lt;p&gt;At present, it‚Äôs better for AI to learn coding within a terminal environment, given that graphics processing is more challenging for existing models. So, let‚Äôs just pick a popular Linux shell, for example, Ubuntu and bash.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;actions&lt;/code&gt; can be structured in JSON format. AI can produce actions such as bash command ‚Äògit‚Äô or ‚Äòtree‚Äô. It can also read/write files. The &lt;code class=&quot;highlighter-rouge&quot;&gt;observations&lt;/code&gt; can be the environment‚Äôs stdout/stderr.&lt;/p&gt;

&lt;p&gt;Consider ‚Äúhello, world!‚Äù as a concrete example. Here are potential actions and observations:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    Action: write-file,
    FilePath: /helloworld.py,
    Content: print(‚Äúhello, world!‚Äù)
}
{
    Observation: success
}
{
    Action: bash,
    Command: ls
}
{
    Observation: helloworld.py
}
{
    Action: bash,
    Command: python helloworld.py
}
{
    Observation: hello, world!
}
{
    Action: submit,
    EntryPoint: helloworld.py
}
{
    Observation: success,
    Reward: +1
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As suggested by OpenAI‚Äôs recent concept of &lt;a href=&quot;https://openai.com/research/improving-mathematical-reasoning-with-process-supervision&quot;&gt;Process Supervision&lt;/a&gt;, dense rewards are likely more effective (but I guess it‚Äôll be more rigid). While creating a curriculum with dense rewards may seem laborious, it may prove beneficial at the outset.&lt;/p&gt;

&lt;p&gt;With our environment established, we can begin design our agent. This agent should make use of both &lt;a href=&quot;https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow#:~:text=Thinking%2C%20Fast%20and%20Slow%20is,more%20deliberative%2C%20and%20more%20logical&quot;&gt;System 1 and System 2&lt;/a&gt;. System 1 is a large neural network model, similar to GPT.&lt;/p&gt;

&lt;p&gt;Designing System 2 is somewhat intricate. Initially, System 2 serves as the glue code between System 1 and the environment. Over time, however, System 1 should learn to bypass some steps of System 2, establishing a more direct connection to the environment. This resembles the way human programmers learn: we start by adhering to rigid rules, then internalize these rules for a more natural/creative/efficient approach. Still, System 1 should periodically consult System 2 to ensure its intuitions are accurate. For instance, System 2 could involve parsing observation JSON, formulating prompts, organizing output into action JSON. But these steps are skippable, the model might sometimes use the raw observation JSON as input without prior prompts.&lt;/p&gt;

&lt;p&gt;Once we have our environment and agent, we can initiate our RL training process. Hopefully, the agent can successfully complete the curriculum and become a real programmer!&lt;/p&gt;

&lt;p&gt;During RL training, System 1 continually improves, while System 2 remains constant. So perhaps, upon graduation, the agent‚Äôs first task should be to rewrite its System 2, then revisit the training process? üôÇ&lt;/p&gt;

&lt;p&gt;Any feedback? We can discuss it under &lt;a href=&quot;https://twitter.com/liusida2007/status/1658114711605354499&quot;&gt;this Tweet. &lt;i class=&quot;fab fa-twitter&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;</content><author><name>Sida Liu (with the help of ChatGPT)</name></author><category term="AI" /><summary type="html">What are the required skills for a being to be a programmer?</summary></entry><entry><title type="html">GFW Causes ElectronJS Installation Failure</title><link href="http://172.25.168.122:4000/coding/2023/06/01/npm-i-electron/" rel="alternate" type="text/html" title="GFW Causes ElectronJS Installation Failure" /><published>2023-06-01T00:00:00+08:00</published><updated>2023-06-01T00:00:00+08:00</updated><id>http://172.25.168.122:4000/coding/2023/06/01/npm-i-electron</id><content type="html" xml:base="http://172.25.168.122:4000/coding/2023/06/01/npm-i-electron/">&lt;p&gt;If you experience something like this when installing &lt;code class=&quot;highlighter-rouge&quot;&gt;electron&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~/code/try-electron&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;npm &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;electron
npm ERR! code 1
npm ERR! path /home/liusida/code/try-electron/node_modules/electron
npm ERR! &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;failed
npm ERR! &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; node install.js
npm ERR! RequestError: Socket connection &lt;span class=&quot;nb&quot;&gt;timeout
&lt;/span&gt;npm ERR!     at ClientRequest.&amp;lt;anonymous&amp;gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/home/liusida/code/try-electron/node_modules/got/dist/source/core/index.js:970:111&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at Object.onceWrapper &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:events:626:26&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at ClientRequest.emit &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:events:523:35&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at origin.emit &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/home/liusida/code/try-electron/node_modules/@szmarczak/http-timer/dist/source/index.js:43:20&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at TLSSocket.socketErrorListener &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:_http_client:495:9&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at TLSSocket.emit &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:events:511:28&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at emitErrorNT &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/streams/destroy:151:8&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at emitErrorCloseNT &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/streams/destroy:116:3&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at process.processTicksAndRejections &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/process/task_queues:82:21&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at new NodeError &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/errors:399:5&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at internalConnectMultiple &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:net:1099:20&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at Timeout.internalConnectMultipleTimeout &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:net:1638:3&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at listOnTimeout &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/timers:575:11&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
npm ERR!     at process.processTimers &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/timers:514:7&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

npm ERR! A &lt;span class=&quot;nb&quot;&gt;complete &lt;/span&gt;log of this run can be found &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;: /home/liusida/.npm/_logs/2023-06-01T12_35_24_835Z-debug-0.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Or something like this:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PS C:&lt;span class=&quot;se&quot;&gt;\c&lt;/span&gt;ode&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;ry-electron&amp;gt; npm &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;electron
RequestError: connect ETIMEDOUT 20.205.243.166:443
    at ClientRequest.&amp;lt;anonymous&amp;gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;C:&lt;span class=&quot;se&quot;&gt;\c&lt;/span&gt;ode&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;ry-electron&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;ode_modules&lt;span class=&quot;se&quot;&gt;\g&lt;/span&gt;ot&lt;span class=&quot;se&quot;&gt;\d&lt;/span&gt;ist&lt;span class=&quot;se&quot;&gt;\s&lt;/span&gt;ource&lt;span class=&quot;se&quot;&gt;\c&lt;/span&gt;ore&lt;span class=&quot;se&quot;&gt;\i&lt;/span&gt;ndex.js:970:111&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at Object.onceWrapper &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:events:628:26&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at ClientRequest.emit &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:events:525:35&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at origin.emit &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;C:&lt;span class=&quot;se&quot;&gt;\c&lt;/span&gt;ode&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;ry-electron&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;ode_modules&lt;span class=&quot;se&quot;&gt;\@&lt;/span&gt;szmarczak&lt;span class=&quot;se&quot;&gt;\h&lt;/span&gt;ttp-timer&lt;span class=&quot;se&quot;&gt;\d&lt;/span&gt;ist&lt;span class=&quot;se&quot;&gt;\s&lt;/span&gt;ource&lt;span class=&quot;se&quot;&gt;\i&lt;/span&gt;ndex.js:43:20&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at TLSSocket.socketErrorListener &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:_http_client:502:9&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at TLSSocket.emit &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:events:513:28&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at emitErrorNT &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/streams/destroy:151:8&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at emitErrorCloseNT &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/streams/destroy:116:3&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at process.processTicksAndRejections &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:internal/process/task_queues:82:21&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    at TCPConnectWrap.afterConnect &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;as oncomplete] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;node:net:1494:16&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Remember, it is not your fault! It is due to the GFW!&lt;/p&gt;

&lt;p&gt;ElectronJS only stores some scripts on npmjs‚Äôs server. When executin &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install electron&lt;/code&gt;, it first fetches those scripts. The &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file defines &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;postinstall&quot;: &quot;node install.js&quot;&lt;/code&gt;. And in &lt;code class=&quot;highlighter-rouge&quot;&gt;install.js&lt;/code&gt;, it downloads artifacts (a .zip file) from GitHub (the url, for example, is like ) and extract it into a subfolder called &lt;code class=&quot;highlighter-rouge&quot;&gt;dist&lt;/code&gt;. If any problem arises, npm will delete all the folders, leaving you without an opportunity to manually rectify this issue.&lt;/p&gt;

&lt;p&gt;To address this, you can use &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install electron --ignore-scripts&lt;/code&gt; to prevent &lt;code class=&quot;highlighter-rouge&quot;&gt;npm&lt;/code&gt; from calling &lt;code class=&quot;highlighter-rouge&quot;&gt;node install.js&lt;/code&gt;. Then, you can try using &lt;code class=&quot;highlighter-rouge&quot;&gt;node ./node_modules/electron/install.js&lt;/code&gt; to see if there‚Äôs any luck. Otherwise, try to download &lt;code class=&quot;highlighter-rouge&quot;&gt;'https://github.com/electron/electron/releases/download/v25.0.1/electron-v25.0.1-linux-x64.zip'&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;https://github.com/electron/electron/releases/download/v25.0.1/electron-v25.0.1-win32-x64.zip&lt;/code&gt; manually, and extract them into a folder called &lt;code class=&quot;highlighter-rouge&quot;&gt;dist&lt;/code&gt;, and copy that folder into the &lt;code class=&quot;highlighter-rouge&quot;&gt;electron&lt;/code&gt; folder as &lt;code class=&quot;highlighter-rouge&quot;&gt;./node_modules/electron/dist/&lt;/code&gt;. Finally, create a &lt;code class=&quot;highlighter-rouge&quot;&gt;path.txt&lt;/code&gt; in the folder &lt;code class=&quot;highlighter-rouge&quot;&gt;.node_modules/electron/&lt;/code&gt;, the content of the &lt;code class=&quot;highlighter-rouge&quot;&gt;path.txt&lt;/code&gt; is simply the name of the electron executable, such as &lt;code class=&quot;highlighter-rouge&quot;&gt;electron.exe&lt;/code&gt; for Windows and &lt;code class=&quot;highlighter-rouge&quot;&gt;electron&lt;/code&gt; for Linux.&lt;/p&gt;

&lt;p&gt;Hope this helps.&lt;/p&gt;</content><author><name>Sida Liu (with the help of ChatGPT)</name></author><category term="Coding" /><summary type="html">If you experience something like this when installing electron:</summary></entry><entry><title type="html">Understanding ‚ÄòA Thousand Brains‚Äô, A Personal Review</title><link href="http://172.25.168.122:4000/reading/2023/05/15/Hawkins-Thousand-Brains-book/" rel="alternate" type="text/html" title="Understanding 'A Thousand Brains', A Personal Review" /><published>2023-05-15T00:00:00+08:00</published><updated>2023-05-15T00:00:00+08:00</updated><id>http://172.25.168.122:4000/reading/2023/05/15/Hawkins-Thousand-Brains-book</id><content type="html" xml:base="http://172.25.168.122:4000/reading/2023/05/15/Hawkins-Thousand-Brains-book/">&lt;p&gt;I recently finished reading Jeff Hawkins‚Äôs book, &lt;em&gt;A Thousand Brains&lt;/em&gt;. I found this book to be incredibly enlightening, introducing a new framework for understanding the brain. This innovative perspective deepened my comprehension of the subject, transforming my previously vague notions about the brain into tangible, concrete concepts.&lt;/p&gt;

&lt;p&gt;In this article, I will summarize the concepts presented in the first part of the book, starting from the level of the whole brain and gradually delving deeper until we reach the level of an individual neuron.&lt;/p&gt;

&lt;p&gt;Our brain can be divided into two parts: the neocortex, which Hawkins refers to as ‚Äúthe new brain‚Äù, and everything else, which was referred to as ‚Äúthe old brain‚Äù.&lt;/p&gt;

&lt;p&gt;The old brain, having evolved earlier in animals, is found in fish, birds, and reptiles. It is responsible for controlling emotions, desires, body movement, and the like.&lt;/p&gt;

&lt;p&gt;On the other hand, the new brain evolved later and is exclusive to mammals. It enables the formation of ideas, languages, concepts, and more.&lt;/p&gt;

&lt;p&gt;Structurally, the new brain envelops the old brain and is connected to it via numerous neural links, facilitating communication between the two.&lt;/p&gt;

&lt;p&gt;If we were to flatten the neocortex, it would be, as Hawkins describes, ‚Äúapproximately the size of a large dinner napkin and twice as thick (about 2.5 mm)‚Äù. Imagine numerous circles on this napkin. Each circle corresponds to a structure called a cortical column, which measures about 1mm wide and 2.5mm high.&lt;/p&gt;

&lt;p&gt;The main premise of the book is that this &lt;strong&gt;cortical column&lt;/strong&gt; functions as &lt;strong&gt;the fundamental computational unit of the brain&lt;/strong&gt;. The brain has approximately 150,000 cortical columns, each of them functioning like a mini-brain, capable of storing hundreds of different models and making predictions based on its input. This is why the book is titled ‚ÄúA Thousand Brains‚Äù.&lt;/p&gt;

&lt;p&gt;A cortical column consists of multiple layers. Two important layers are discussed in the book. The upper layer receives sensory information while the lower layer receives movement information. Hawkins explains, ‚ÄúThe basic flow of information goes as follows: A sensory input arrives and is represented by the neurons in the upper layer. This invokes the location in the lower layer that is associated with the input. When movement occurs, such as moving a finger, then the lower layer changes to the expected new location, which causes a prediction of the next input in the upper layer.‚Äù&lt;/p&gt;

&lt;p&gt;This is analogous to the place cells and grid cells in the old brain, which provide animals with a sense of their location in the environment. However, whereas we have only one set of place cells and grid cells in the old brain, in the neocortex, we have a set of cortical place cells and cortical grid cells in &lt;em&gt;every&lt;/em&gt; cortical column. When we interact with a coffee cup, for instance, the relevant cortical columns become active. Thanks to the cortical place cells and cortical grid cells, these columns can determine that the current sensory input corresponds to a certain point in the model, and when movement occurs, they can predict what sensory input will come next.&lt;/p&gt;

&lt;p&gt;Cortical columns complement each other. Each object is stored ‚Äúin many, but not too many, columns‚Äù simultaneously. This distributed storage system is both efficient and robust. Each perception or thought results from a consensus reached by the relevant columns through a process akin to voting. The ‚Äòvoting‚Äô neurons act as representatives of a cortical column, broadcasting the column‚Äôs prediction through long-distance axons connected to other cortical columns.&lt;/p&gt;

&lt;p&gt;It‚Äôs easy to see how this would work with everyday objects, like a coffee cup. However, this process also applies to objects we can‚Äôt see, such as a DNA molecule. We tend to visualize these invisible objects, allowing the cortical columns to form reference frames for these mental models.&lt;/p&gt;

&lt;p&gt;Furthermore, the same method can handle abstract concepts. Instead of using a 2D or 3D physical space as a reference frame, a cortical column can create novel reference frames for abstract concepts. For example, when we think about political opinions, we might use the political spectrum to form a 1D space, with each opinion placed at a specific point on that spectrum. If we treat one opinion as an object, then the political spectrum represents one of the dimensions of the space in which the model lives. As our thoughts drift from one abstract concept to another, it‚Äôs as though we‚Äôre moving through one dimension of this abstract space, encountering new concepts along the way.&lt;/p&gt;

&lt;p&gt;As Hawkins explains, ‚ÄúThis is one reason that learning conceptual knowledge can be difficult. ‚Ä¶ Part of the learning is discovering what constitutes a good reference frame, including the number of dimensions. ‚Ä¶ Becoming an expert in a field of study requires discovering an effective framework to represent the associated data and facts.‚Äù&lt;/p&gt;

&lt;p&gt;Cortical columns are composed of tens of thousands of neurons. According to the book, the model of the current artificial neural network doesn‚Äôt accurately reflect the structure and function of these neurons, and it proposes that we need a better model.&lt;/p&gt;

&lt;p&gt;A neuron has many dendrites, with the vast majority of synapses‚Äîabout 90%‚Äîlocated on these dendrites. When these synapses are activated, they trigger dendritic spikes that travel from the synapses to the cell body. Although these spikes don‚Äôt cause the neuron to fire, they make it easier and quicker for the neuron to fire. This process helps explain the phenomenon of priming in cognitive psychology. The remaining 10% of synapses, known as proximal synapses, are located near the cell body and are modeled as the input in the artificial neural network. In essence, the dendritic synapses prime the neuron, and the proximal synapses trigger the action potential. Without the dendritic synapses, the input would be too ambiguous for the neuron to generate a prediction.&lt;/p&gt;

&lt;p&gt;The concepts outlined above comprise only the first part of the book, focusing on how the brain works. The latter part of the book, although equally fascinating and convincing, takes a more subjective approach, so I‚Äôve chosen to exclude it from this summary.&lt;/p&gt;

&lt;p&gt;To me, this framework is incredibly compelling. One of the most fascinating aspects of neuroscience is the sheer abundance of research papers containing a wealth of experimental data. Researchers measure various aspects of the brain and document their findings. This means that anyone can study neuroscience by reading these papers and forming their own theories about the brain. I‚Äôm excited to learn more about the brain and see how I can incorporate additional knowledge and information into this framework.&lt;/p&gt;

&lt;p&gt;P.S. An interesting side note: The author of &lt;a href=&quot;https://liusida.github.io/reading/2023/05/07/tegmark-mathematical-universe-book/&quot;&gt;the book I read a week earlier&lt;/a&gt;, Max Tegmark, expresses significant concern about the existential risks introduced by artificial intelligence. Conversely, Jeff Hawkins sits on the other end of the spectrum, exuding optimism about the development of artificial intelligence. Both authors are very thoughtful and reasonable, yet it‚Äôs fascinating to see how they‚Äôve arrived at vastly different opinions about the existential risk posed by AI.&lt;/p&gt;

&lt;p&gt;Any feedback? We can discuss it under &lt;a href=&quot;https://twitter.com/liusida2007/status/1658114711605354499&quot;&gt;this Tweet. &lt;i class=&quot;fab fa-twitter&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;</content><author><name>Sida Liu (with the help of ChatGPT)</name></author><category term="Reading" /><summary type="html">I recently finished reading Jeff Hawkins‚Äôs book, A Thousand Brains. I found this book to be incredibly enlightening, introducing a new framework for understanding the brain. This innovative perspective deepened my comprehension of the subject, transforming my previously vague notions about the brain into tangible, concrete concepts.</summary></entry><entry><title type="html">A Personal Journey Through Tegmark‚Äôs Mathematical Universe</title><link href="http://172.25.168.122:4000/reading/2023/05/07/tegmark-mathematical-universe-book/" rel="alternate" type="text/html" title="A Personal Journey Through Tegmark's Mathematical Universe" /><published>2023-05-07T00:00:00+08:00</published><updated>2023-05-07T00:00:00+08:00</updated><id>http://172.25.168.122:4000/reading/2023/05/07/tegmark-mathematical-universe-book</id><content type="html" xml:base="http://172.25.168.122:4000/reading/2023/05/07/tegmark-mathematical-universe-book/">&lt;p&gt;I recently finished reading Max Tegmark‚Äôs book &lt;em&gt;Our Mathematical Universe: My Quest for the Ultimate Nature of Reality&lt;/em&gt;, and I found it to be a truly amazing and transformative experience. This book, along with &lt;em&gt;Complexity: A Guided Tour&lt;/em&gt; by Melanie Mitchell, which I read several years ago, has had a significant impact on my understanding of the world and my intellectual journey.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Our Mathematical Universe&lt;/em&gt; has provided clarity for several of the big questions that have been troubling me since grad school. I had expressed to my advisor, Josh, that my interests felt too broad‚ÄîI wanted to understand intelligence, life, and reality, as well as build artificial versions of each to learn from the process. This book has helped to clear up much of my confusion and guide me in my pursuit of these answers.&lt;/p&gt;

&lt;p&gt;Tegmark‚Äôs book starts by exploring reality from various angles.&lt;/p&gt;

&lt;p&gt;First, the book takes a cosmological perspective, delving into the history of our universe. It explains how physicists have been able to extrapolate the 14-billion-year history of our observable universe, leading to the conclusion that the universe began with &lt;em&gt;the Big Bang&lt;/em&gt;. Years ago, I was skeptical about the Big Bang theory because it seemed like an extreme extrapolation that went too far. However, the book provides a wealth of evidence to support this theory, specifically, our observable universe seems to be quite flat in spacetime, and I now find the extrapolation quite convincing.&lt;/p&gt;

&lt;p&gt;The book also introduces &lt;em&gt;the inflation theory&lt;/em&gt;, developed in 1979, as a potential explanation for the cause of the Big Bang. According to this theory, the universe underwent rapid expansion due to the doubling of matter in every dimension. This idea is compatible with general relativity and has gained acceptance among many physicists. I personally find this theory satisfying and see it as a potential starting point for further exploration if I want to delve into cosmology.&lt;/p&gt;

&lt;p&gt;Next, Tegmark delves into the microscopic world, discussing the debate between Einstein and Bohr over the nature of quantum mechanics. When I first learned this debate years ago, I had initially sided with Einstein, believing that there must be some mechanisms behind the apparent randomness of quantum mechanics‚Äì‚ÄúGod does not play dice with the universe‚Äù. The book introduces Everett‚Äôs &lt;em&gt;Many Worlds interpretation&lt;/em&gt;, first proposed in 1957, which posits that the wavefunction never collapses and that parallel universes exist. I find this idea intriguing and think that Einstein might have appreciated it as well. In comparison, the widely accepted &lt;em&gt;Copenhagen interpretation&lt;/em&gt;, dating back to the 1920s, seems more like a higher-level model of reality‚Äîuseful, but not the ultimate.&lt;/p&gt;

&lt;p&gt;Additionally, the book covers the concept of &lt;em&gt;decoherence&lt;/em&gt;, which explains why we don‚Äôt observe quantum superposition on a macroscopic scale. This idea was first introduced in 1970 by H. Dieter Zeh, but Tegmark also discovered this independently. Decoherence is now well-accepted in the field and could serve as a starting point for further investigation if I want to delve into the microscopic realm.&lt;/p&gt;

&lt;p&gt;Tegmark takes a step back and discusses three different types of reality: internal, external, and consensus reality. &lt;em&gt;Internal reality&lt;/em&gt; is what we perceive and the world model created in our brain, akin to Anil Seth‚Äôs ‚Äúcontrolled hallucination‚Äù, while &lt;em&gt;external reality&lt;/em&gt; is the ultimate, objective, independent reality. &lt;em&gt;Consensus reality&lt;/em&gt; lies somewhere in between, as it is the shared understanding of reality among people. The idea of consensus reality particularly resonates with me, as it seems to be the most important reality for ordinary people. For example, a wall is a wall not because it exists independently from human observers, but because most people agree that it is a wall. However, at a more fundamental level, we know that it is just a collection of protons, neutrons, and electrons.&lt;/p&gt;

&lt;p&gt;The book proposes that the ultimate external reality is a mathematical object, which is an intriguing but speculative idea. While I am open to the possibility, I would like to see more evidence before fully accepting it.&lt;/p&gt;

&lt;p&gt;In discussing the mathematical nature of reality, Tegmark emphasizes the distinction between &lt;em&gt;mathematical structures&lt;/em&gt; and their &lt;em&gt;descriptions&lt;/em&gt;. For example, the ideas of addition and multiplication are the structures, and we can describe them using either natural language, like ancient Greeks did, or using equations, like modern students do. The description can vary from culture to culture, but the mathematical structure doesn‚Äôt change. He also explores the fundamental properties of mathematical structures, such as &lt;em&gt;symmetry&lt;/em&gt; and &lt;em&gt;relation&lt;/em&gt;. Regardless of whether mathematics is the ultimate reality or merely describes the reality, his elaboration deepens my understanding of mathematics.&lt;/p&gt;

&lt;p&gt;Finally, the book touches on fascinating topics inside the reality, like the nature of life and consciousness. Tegmark suggests that &lt;em&gt;life&lt;/em&gt; is not a binary category but a spectrum defined by complexity. Similarly, he proposes that &lt;em&gt;consciousness&lt;/em&gt; arises from the brain‚Äôs computational processes as a byproduct of understanding the self and the world.&lt;/p&gt;

&lt;p&gt;While I have chosen to disregard some of the more speculative ideas in the book, the concepts that resonated with me have significantly influenced my understanding of the world. I feel incredibly fortunate to have encountered so many valuable ideas in one book. As I continue my intellectual journey, I eagerly anticipate reading more works by Max Tegmark and others who delve into these fascinating subjects.&lt;/p&gt;

&lt;p&gt;Any feedback? We can discuss it under &lt;a href=&quot;https://twitter.com/liusida2007/status/1655240922521800704&quot;&gt;this Tweet. &lt;i class=&quot;fab fa-twitter&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;</content><author><name>Sida Liu (with the help of ChatGPT)</name></author><category term="Reading" /><summary type="html">I recently finished reading Max Tegmark‚Äôs book Our Mathematical Universe: My Quest for the Ultimate Nature of Reality, and I found it to be a truly amazing and transformative experience. This book, along with Complexity: A Guided Tour by Melanie Mitchell, which I read several years ago, has had a significant impact on my understanding of the world and my intellectual journey.</summary></entry><entry><title type="html">Validate HLSL grammar in command line</title><link href="http://172.25.168.122:4000/gpu/2021/10/11/validate-hlsl-grammar-in-command-line/" rel="alternate" type="text/html" title="Validate HLSL grammar in command line" /><published>2021-10-11T00:00:00+08:00</published><updated>2021-10-11T00:00:00+08:00</updated><id>http://172.25.168.122:4000/gpu/2021/10/11/validate-hlsl-grammar-in-command-line</id><content type="html" xml:base="http://172.25.168.122:4000/gpu/2021/10/11/validate-hlsl-grammar-in-command-line/">&lt;p&gt;HLSL, a.k.a. High-level shader language, is used in Unity.&lt;/p&gt;

&lt;p&gt;One can write the shader in Unity (with VS or VSCode) and compile it automatically in Unity. If there‚Äôs any error in the shader code, the error message will show up in the Unity console.&lt;/p&gt;

&lt;p&gt;However, since I am using a Linux, I can‚Äôt debug the shader in Unity.
So I turn to a light-weight tool called SHADERed.
One can install the SHADERed plug-in in VSCode along with SHADERed, and voil√†, we can debug the shader code!&lt;/p&gt;

&lt;p&gt;So we can write HLSL in VSCode and SHADERed first, and then copy it to Unity shader and modify it to be compatible.&lt;/p&gt;

&lt;p&gt;Here is a cool video shows how to do the modification, it even works with GLSL.
&lt;a href=&quot;https://www.youtube.com/watch?v=CzORVWFvZ28&quot;&gt;Youtube: How to convert a shader from ShaderToy to Unity&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now my problem was that SHADERed won‚Äôt show the detailed compilation error if there‚Äôs any error in the shader code. It just says, ‚ÄúCan not display preview - there are some errors you should fix.‚Äù&lt;/p&gt;

&lt;p&gt;So I digged in a bit, and realized that both Unity and SHADERed use &lt;a href=&quot;https://github.com/KhronosGroup/glslang&quot;&gt;glslang&lt;/a&gt; to compile the shader code.&lt;/p&gt;

&lt;p&gt;Luckily, glslang provide a standalone executable that can compile the shader code as a showcase of how to use the glslang API. It is called &lt;code class=&quot;highlighter-rouge&quot;&gt;glslangValidator&lt;/code&gt;. I am on Ubuntu, so I can get this tool by simply &lt;code class=&quot;highlighter-rouge&quot;&gt;apt install glslang-tools&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;So for example we want to validate this piece of fragment shader named &lt;code class=&quot;highlighter-rouge&quot;&gt;2d_SimplePS.hlsl&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cbuffer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;register&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;float2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uResolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragCoord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SV_POSITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SV_TARGET&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragCoord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uResolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uResolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uResolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;here&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intentional&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And we use the command:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# look it up using `man glslangValidator`&lt;/span&gt;
glslangValidator &lt;span class=&quot;nt&quot;&gt;-S&lt;/span&gt; frag &lt;span class=&quot;nt&quot;&gt;-D&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--client&lt;/span&gt; vulkan100 &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; frag 2d_SimplePS.hlsl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and the compiler will show the error message:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2d_SimplePS.hlsl
ERROR: 2d_SimplePS.hlsl:12: &lt;span class=&quot;s1&quot;&gt;'here'&lt;/span&gt; : unknown variable 
ERROR: 2d_SimplePS.hlsl:12: &lt;span class=&quot;s1&quot;&gt;';'&lt;/span&gt; : Expected 
2d_SimplePS.hlsl&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;12&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: error at column 11, HLSL parsing failed.
ERROR: 3 compilation errors.  No code generated.

SPIR-V is not generated &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;failed compile or &lt;span class=&quot;nb&quot;&gt;link&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We have the file name, line number, and the detailed error messages. Great!&lt;/p&gt;</content><author><name>Sida Liu</name></author><category term="GPU" /><summary type="html">HLSL, a.k.a. High-level shader language, is used in Unity.</summary></entry><entry><title type="html">Setup Unity ML-Agents</title><link href="http://172.25.168.122:4000/simulation/2021/09/23/setup-unity-ml-agents/" rel="alternate" type="text/html" title="Setup Unity ML-Agents" /><published>2021-09-23T00:00:00+08:00</published><updated>2021-09-23T00:00:00+08:00</updated><id>http://172.25.168.122:4000/simulation/2021/09/23/setup-unity-ml-agents</id><content type="html" xml:base="http://172.25.168.122:4000/simulation/2021/09/23/setup-unity-ml-agents/">&lt;p&gt;Unity has published ML-Agents 2.x which can do reinforcement learning on Unity environment. Here is the &lt;a href=&quot;https://github.com/Unity-Technologies/ml-agents&quot;&gt;GitHub Repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To set everything up, we first need to install Unity. I have installed 2020.3.18f1 LTS version to my Ubuntu 20.04 from Unity Hub.&lt;/p&gt;

&lt;p&gt;Then, we need to clone the &lt;a href=&quot;https://github.com/Unity-Technologies/ml-agents&quot;&gt;ML-Agents 2.x GitHub Repo&lt;/a&gt;, for example, to &lt;code class=&quot;highlighter-rouge&quot;&gt;~/code/ml-agents/&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Create a new Unity project, drag the folder &lt;code class=&quot;highlighter-rouge&quot;&gt;~/code/ml-agents/Project/Assets/ML-Agents/Examples&lt;/code&gt; to the Unity Assets, right beside the &lt;code class=&quot;highlighter-rouge&quot;&gt;Scenes&lt;/code&gt; folder.&lt;/p&gt;

&lt;p&gt;Then, we need to install some packages to Unity. Click on the menu &lt;code class=&quot;highlighter-rouge&quot;&gt;Window&lt;/code&gt;-&amp;gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Package Manager&lt;/code&gt;, select &lt;code class=&quot;highlighter-rouge&quot;&gt;Packages: In Project&lt;/code&gt;, click the &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; on its left, &lt;code class=&quot;highlighter-rouge&quot;&gt;Add package from disk...&lt;/code&gt;, and choose the &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;~/code/ml-agents/com.unity.ml-agents/&lt;/code&gt; folder, install it. Click the &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Add package from disk...&lt;/code&gt; again, and choose the &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;~/code/ml-agents/com.unity.ml-agents.extensions/&lt;/code&gt; folder, install it as well.
&lt;img src=&quot;/images/2021-09-23/package-manager.png&quot; alt=&quot;packagemanager&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We also need another package from &lt;code class=&quot;highlighter-rouge&quot;&gt;Unity Registry&lt;/code&gt;. Search for &lt;code class=&quot;highlighter-rouge&quot;&gt;Input System&lt;/code&gt;, and install that.
&lt;img src=&quot;/images/2021-09-23/input-system.png&quot; alt=&quot;input-system&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We would notice that there are still errors in the console. It seems that there are some incompatible code in the example &lt;code class=&quot;highlighter-rouge&quot;&gt;PushBlockWithInput&lt;/code&gt;. I simply delete that example in &lt;code class=&quot;highlighter-rouge&quot;&gt;Assets&lt;/code&gt;. (There is one folder called &lt;code class=&quot;highlighter-rouge&quot;&gt;Assets/Examples/SharedAssets&lt;/code&gt;, it must be included.)&lt;/p&gt;

&lt;p&gt;Now, if we open the scene &lt;code class=&quot;highlighter-rouge&quot;&gt;Assets/Examples/3DBall/Scenes/3DBall.unity&lt;/code&gt;, we can click play to see the pre-trained model controling the robots. (Although there are still many error messages. ;)
&lt;img src=&quot;/images/2021-09-23/3dball.png&quot; alt=&quot;3dball&quot; /&gt;&lt;/p&gt;</content><author><name>Sida Liu</name></author><category term="Simulation" /><summary type="html">Unity has published ML-Agents 2.x which can do reinforcement learning on Unity environment. Here is the GitHub Repo.</summary></entry><entry><title type="html">A simple Android virtual environment</title><link href="http://172.25.168.122:4000/simulation/2021/07/03/simple-android-env-copy/" rel="alternate" type="text/html" title="A simple Android virtual environment" /><published>2021-07-03T00:00:00+08:00</published><updated>2021-07-03T00:00:00+08:00</updated><id>http://172.25.168.122:4000/simulation/2021/07/03/simple-android-env%20copy</id><content type="html" xml:base="http://172.25.168.122:4000/simulation/2021/07/03/simple-android-env-copy/">&lt;p&gt;Creating an intelligent agent that can browse the internet like a human user does is interesting.
Many websites don‚Äôt want to provide services to artificial agents, but my opinion is that, making AI that can acqure information like human will facilitate the communication between AI and human, providing a common ground for both parties.&lt;/p&gt;

&lt;p&gt;Recently, DeepMind has open-sourced a &lt;a href=&quot;https://github.com/deepmind/android_env/&quot;&gt;virtual Android environment for RL agents&lt;/a&gt;.
Comparing to a virtual PC, a Android emulator tends to be faster.
Moreover, some applications only provide interface on mobile devices.
So I found this project interesting.&lt;/p&gt;

&lt;p&gt;However, I am not familiar with Android, so the whole project is a little too complicated to me.
I decide to make a toy/simplified version of this project, just to learn more about the details.&lt;/p&gt;

&lt;p&gt;First of all, this project doesn‚Äôt include the emulator of Android, rather, we need to &lt;a href=&quot;https://github.com/deepmind/android_env/blob/main/docs/emulator_guide.md&quot;&gt;install the emulator from Android Studio&lt;/a&gt;.
Once we created an AVD (Android Virtual Device), we should be able to start the device by this command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~/Android/Sdk/emulator/emulator &lt;span class=&quot;nt&quot;&gt;-avd&lt;/span&gt; my_device
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;suppose the emulator was installed into &lt;code class=&quot;highlighter-rouge&quot;&gt;~/Android/Sdk/emulator&lt;/code&gt; folder, and &lt;code class=&quot;highlighter-rouge&quot;&gt;my_device&lt;/code&gt; is the name of the AVD I created.&lt;/p&gt;

&lt;p&gt;However, the guide suggests that we should start the AVD from Android Studio. I am not sure why we should not start the emulator without Android Studio.
If you happen to know why, please let me know.&lt;/p&gt;

&lt;p&gt;You can probably see a GUI like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/2021-07-03-simple-android-env/avd.png&quot; alt=&quot;avd&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And you can use your mouse and keyboard to play with this virtual device.&lt;/p&gt;

&lt;p&gt;Then, we will want to send mouse and keyboard events to the virtual device programmably.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.android.com/studio/run/emulator-console&quot;&gt;Here&lt;/a&gt; is a documentation for how to send commands to the emulator. 
However, this is a very simple explanation of the commands, and it is not clear how to send mouse events (with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;event&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;After reading this &lt;a href=&quot;https://github.com/deepmind/android_env/blob/main/android_env/components/emulator_console.py#L244&quot;&gt;source file&lt;/a&gt; from the AndroidEnv, I discovered that we can use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;event mouse&lt;/code&gt; to send mouse events to the virtual device.
This is not mentioned in the documentation, and I don‚Äôt know why.&lt;/p&gt;

&lt;p&gt;Once we are able to send events (actions) to the virtual device, we also would like to get the feedback from the device.
According to the documentation, the way we can achieve that is using the &lt;code class=&quot;highlighter-rouge&quot;&gt;screenrecord screenshot&lt;/code&gt; command.
However, this command only takes a path to a folder as its parameter (not a path to a file) and doesn‚Äôt return the filename it has created, so we need to clean the folder beforehand and probably use &lt;code class=&quot;highlighter-rouge&quot;&gt;glob&lt;/code&gt; to get whatever created in that folder after the command returns.
Also, the command returns before the file has been created, so one need to make sure the file has been created before using &lt;code class=&quot;highlighter-rouge&quot;&gt;glob&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The file created by &lt;code class=&quot;highlighter-rouge&quot;&gt;screenrecord&lt;/code&gt; is a PNG file, and we can use, for example, Python package &lt;code class=&quot;highlighter-rouge&quot;&gt;imageio&lt;/code&gt; to read that file as a Numpy array, and feed that to the neural network.&lt;/p&gt;

&lt;p&gt;Now we have actions and observations, and this is basically the simplest version of an Android envrionment.
Instead of using &lt;a href=&quot;https://github.com/deepmind/android_env/&quot;&gt;DeepMind/AndroidEnv&lt;/a&gt;, we can manipulate the virtual device directly.&lt;/p&gt;

&lt;p&gt;I‚Äôll be happy to see some intelligent agents that can operate the virtual mobile phone and discover the Internet on their own in a more human-like way.&lt;/p&gt;</content><author><name>Sida Liu</name></author><category term="Simulation" /><summary type="html">Creating an intelligent agent that can browse the internet like a human user does is interesting. Many websites don‚Äôt want to provide services to artificial agents, but my opinion is that, making AI that can acqure information like human will facilitate the communication between AI and human, providing a common ground for both parties.</summary></entry><entry><title type="html">How to use PyCUDA to bring significant speedup</title><link href="http://172.25.168.122:4000/cuda/2020/08/02/pycuda/" rel="alternate" type="text/html" title="How to use PyCUDA to bring significant speedup" /><published>2020-08-02T00:00:00+08:00</published><updated>2020-08-02T00:00:00+08:00</updated><id>http://172.25.168.122:4000/cuda/2020/08/02/pycuda</id><content type="html" xml:base="http://172.25.168.122:4000/cuda/2020/08/02/pycuda/">&lt;p&gt;Imagine that we have designed an computational experiment in Python, and we waited 3 days for the results, and after that, unfortunately we discovered there was a typo or a small bug in the source code. What do you think we would say when we restart the experiment? I would hope that the experiment could be run in half a hour.&lt;/p&gt;

&lt;p&gt;It is possible, by making the code parallized.&lt;/p&gt;

&lt;p&gt;CUDA is a C++-like program language for parallel programs which can run on Nvidia GPU. &lt;a href=&quot;https://developer.nvidia.com/cuda-toolkit&quot;&gt;CUDA website&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PyCUDA is an open source Python interface to compile CUDA source code on the fly and execute it. &lt;a href=&quot;https://documen.tician.de/pycuda/&quot;&gt;PyCUDA documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here we show an example of using CUDA and PyCUDA to rewrite a Python program.&lt;/p&gt;

&lt;p&gt;Source code: &lt;a href=&quot;https://github.com/liusida/JacksCarRental-via-PyCUDA&quot;&gt;GitHub repo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The file &lt;code class=&quot;highlighter-rouge&quot;&gt;car_rental.py&lt;/code&gt; is a Python program. It is slow because there are huge nested loops. We can exam this by searching for the keywords &lt;code class=&quot;highlighter-rouge&quot;&gt;while True&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The file &lt;code class=&quot;highlighter-rouge&quot;&gt;car_rental_cuda.py&lt;/code&gt; is the CUDA-optimized version of the original program. The &lt;code class=&quot;highlighter-rouge&quot;&gt;gpu_policy_evaluation&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;gpu_policy_improvement&lt;/code&gt; are two kernels (CUDA interfaces) that can run 21*21 (num_state=21) threads in parallel. In this code, it prepares the pre-defined constant vairables and read in the CUDA source file &lt;code class=&quot;highlighter-rouge&quot;&gt;car_rental_cuda.py.cu&lt;/code&gt;, compiles them on the fly, and expose the interfaces as Python functions.&lt;/p&gt;

&lt;p&gt;By running them, we can get the results in the &lt;code class=&quot;highlighter-rouge&quot;&gt;images/&lt;/code&gt; folder. And we can see the CUDA version only takes 6 seconds while the original version would take more than a hour.&lt;/p&gt;</content><author><name>Sida Liu</name></author><category term="CUDA" /><summary type="html">Imagine that we have designed an computational experiment in Python, and we waited 3 days for the results, and after that, unfortunately we discovered there was a typo or a small bug in the source code. What do you think we would say when we restart the experiment? I would hope that the experiment could be run in half a hour.</summary></entry><entry><title type="html">Nuance in Monty Hall Paradox</title><link href="http://172.25.168.122:4000/old/2018/07/02/nuance-in-monty-hall-paradox/" rel="alternate" type="text/html" title="Nuance in Monty Hall Paradox" /><published>2018-07-02T00:00:00+08:00</published><updated>2018-07-02T00:00:00+08:00</updated><id>http://172.25.168.122:4000/old/2018/07/02/nuance-in-monty-hall-paradox</id><content type="html" xml:base="http://172.25.168.122:4000/old/2018/07/02/nuance-in-monty-hall-paradox/">&lt;p&gt;Marilyn vos Savant has made a mistake. She knew the game show Let‚Äôs Make a Deal too well, that she assumed the rules of the game show also applied to the question she was asked.&lt;/p&gt;

&lt;p&gt;On the website of Marilyn vos Savant, the original question could be found here http://marilynvossavant.com/game-show-problem/ :&lt;/p&gt;

&lt;p&gt;‚ÄúSuppose you‚Äôre on a game show, and you‚Äôre given the choice of three doors. Behind one door is a car, behind the others, goats. You pick a door, say #1, and the host, who knows what‚Äôs behind the doors, opens another door, say #3, which has a goat. He says to you, ‚ÄúDo you want to pick door #2?‚Äù Is it to your advantage to switch your choice of doors?‚Äù&lt;/p&gt;

&lt;p&gt;Interestingly, the original question never indicate any established rules of Let‚Äôs Make a Deal, which is critical to this question. Examination of the original question reveals that the host is not mandatory to open another door, i.e., the host could just open the door that is choosen. In this case, which the host is free to choose opening the door directly or opening another door for you then asking you to switch, his choice of opening another door is probably in order to lead you away from winning the car. (Unforturenately, the rule of winning what ever showed behind the door is not metioned in the question either.)&lt;/p&gt;

&lt;p&gt;For this reason, the ‚ÄúMarilyn‚Äôs question‚Äù is different from ‚ÄúMonty Hall Paradox.‚Äù&lt;/p&gt;

&lt;p&gt;So how to solve ‚ÄúMarilyn‚Äôs question‚Äù?&lt;/p&gt;</content><author><name>Sida Liu</name></author><category term="Old" /><summary type="html">Marilyn vos Savant has made a mistake. She knew the game show Let‚Äôs Make a Deal too well, that she assumed the rules of the game show also applied to the question she was asked.</summary></entry><entry><title type="html">What is Mathematics According to Keith Devlin</title><link href="http://172.25.168.122:4000/old/2018/06/27/what-is-mathematics/" rel="alternate" type="text/html" title="What is Mathematics According to Keith Devlin" /><published>2018-06-27T00:00:00+08:00</published><updated>2018-06-27T00:00:00+08:00</updated><id>http://172.25.168.122:4000/old/2018/06/27/what-is-mathematics</id><content type="html" xml:base="http://172.25.168.122:4000/old/2018/06/27/what-is-mathematics/">&lt;p&gt;‰∏äÂçàËØª‰∫ÜKeith DevlinÊïôÊéàÁöÑËØæÁ®ãËÉåÊôØÊùêÊñôÔºåÊúâÁÇπÊÑüËß¶ÔºåÊëòÊäÑ‰∫ÜÂá†ÊÆµÂØπÊàëÂæàÊúâÂêØÂèëÁöÑÊñáÂ≠óÔºå‰ª•Â§áÊó•ÂêéÂèÇËÄÉ„ÄÇ&lt;/p&gt;

&lt;p&gt;In Keith Devlin‚Äôs book ‚ÄòIntroduction to Mathematical Thinking‚Äô, he writes,&lt;/p&gt;

&lt;p&gt;‚ÄúVirtually nothing (with just two further advances, both from the 17th century: calculus and probability theory) from the last three hundred years has found its way into the classroom. Yet most of the mathematics used in today‚Äôs world was developed in the last two hundred years! As a result, anyone whose view of mathematics is confined to what is typically taught in schools is unlikely to appreciate that research in mathematics is a thriving, worldwide activity, or to accept that mathematics permeates, often to a considerable extent, most walks of present-day life and society.‚Äù&lt;/p&gt;

&lt;p&gt;Â∞èÂ≠¶Âà∞È´ò‰∏≠ËØæÂ†ÇÈáåÊâÄÊ∂âÂèäÂà∞ÁöÑÊï∞Â≠¶ÔºåÂü∫Êú¨ÈÉΩÊòØ‰∏âÁôæÂπ¥ÂâçÁöÑ‰∏úË•ø‰∫ÜÔºåËØ¥‰∏âÁôæÂπ¥ËøòÊòØÁªôÈù¢Â≠ê‰∫ÜÔºåÂõ†‰∏∫‰∏âÁôæÂπ¥ÂâçÁöÑ‰πüÂ∞±ÊòØÂæÆÁßØÂàÜÂíåÊ¶ÇÁéáÔºåÂÖ∂‰ªñÁöÑÂ∞±Êõ¥Âè§ËÄÅ‰∫Ü„ÄÇ‰ΩÜÊòØÂë¢Ôºå‰ªäÂ§©Êàë‰ª¨Âú®Á§æ‰ºö‰∏äÁî®Âà∞ÁöÑÊï∞Â≠¶Â§ßÂ§öÈÉΩÊòØËøë‰∏§ÁôæÂπ¥ÂÜÖÂèëÂ±ïÂá∫Êù•ÁöÑ„ÄÇÊâÄ‰ª•Â¶ÇÊûúËÆ§‰∏∫Êï∞Â≠¶Â∞±ÊòØÊàë‰ª¨‰∏≠Â≠¶ËØæÊú¨ÈáåÊïôÁöÑÈÇ£‰∫õÁöÑËØùÔºåÂ∞±Êó†Ê≥ïÊ¨£ËµèÊúÄÊñ∞ÁöÑÊï∞Â≠¶Á†îÁ©∂ÂèëÂ±ïÂíØ„ÄÇ&lt;/p&gt;

&lt;p&gt;‚Äú‚Ä¶mathematical notation no more is mathematics than musical notation is music. ‚Ä¶ In 1623, Galileo wrote, ‚ÄòThe great book of nature can be read only by those who know the language in which it was written. And this language is mathematics.‚Äô‚Ä¶‚Äù&lt;/p&gt;

&lt;p&gt;ËØ¥Êï∞Â≠¶Á¨¶Âè∑Â∞±ÊòØÊï∞Â≠¶ÔºåÂ∞±Ë∑üËØ¥Èü≥‰πêÁ¨¶Âè∑Â∞±ÊòØÈü≥‰πê‰∏ÄÊ†∑ÔºåÂÖ∂ÂÆû‰ªñÂè™ÊòØÊï∞Â≠¶ÁöÑËØ≠Ë®ÄÔºåÂπ∂‰∏çÊòØÊï∞Â≠¶Êú¨Ë∫´„ÄÇ‰ΩÜÊòØÂë¢Ôºå‰ºΩÂà©Áï•ËØ¥ÔºåËøô‰∏™Ëá™ÁÑ∂ÁïåÊòØÊï∞Â≠¶ÂÜôÊàêÁöÑ„ÄÇÊâÄ‰ª•Â≠¶‰π†Êï∞Â≠¶ËØ≠Ë®ÄÊå∫ÈáçË¶ÅÂïä„ÄÇ&lt;/p&gt;

&lt;p&gt;‚ÄúAs one of the greatest creations of human civilization, mathematics should be taught alongside science, literature, history, and art in order to pass along the jewels of our culture from one generation to the next. We humans are far more than the jobs we do and the careers we pursue.‚Äù&lt;/p&gt;

&lt;p&gt;Êï∞Â≠¶‰Ωú‰∏∫‰∫∫Á±ªÂàõÈÄ†ÁöÑÊúÄ‰ºüÂ§ßÁöÑ‰∏úË•ø‰πã‰∏ÄÔºåË∑üÁßëÂ≠¶„ÄÅÊñáÂ≠¶„ÄÅÂéÜÂè≤ÂíåËâ∫ÊúØ‰∏ÄÂπ∂ÔºåÈÉΩÂ∫îËØ•ÊïôÁªô‰∏ã‰∏Ä‰ª£ÔºåËøôÊòØ‰∫∫Á±ªÊúÄÁèçË¥µÁöÑ‰∏úË•ø‰∫Ü„ÄÇÊàë‰ª¨‰∫∫Á±ªÂòõÔºå‰∏ç‰ªÖ‰ªÖÊòØ‰∏™Âπ≤Ê¥ªÁöÑÂ∑•‰∫∫ÔºåÊàë‰ª¨ÂÄºÊõ¥Â§ö„ÄÇ&lt;/p&gt;

&lt;p&gt;‚Äú‚Ä¶those skills (use mathematics as a tool) fall into two categories. ‚Ä¶ The second category comprises people who can take a new problem, say in manufacturing, identify and describe key features of the problem mathematically, and use that mathematical description to analyze the problem in a precise fashion. ‚Ä¶ I propose to give them one (name): innovative mathematical thinkers.‚Äù&lt;/p&gt;

&lt;p&gt;‰ΩøÁî®Êï∞Â≠¶ÂèØ‰ª•Êúâ‰∏§Á±ªÔºå‰∏ÄÁ±ªÊòØÊãøÂà∞Â∑≤ÁªèÂÆö‰πâÂ•ΩÁöÑÊï∞Â≠¶ÈóÆÈ¢òÊÉ≥ÂäûÊ≥ïËÆ°ÁÆóÁªìÊûúÔºåÁ¨¨‰∫åÁ±ªÊòØÂú®ÂÆûÈôÖÁîüÊ¥ª‰∏≠ÊääÈÅáÂà∞ÁöÑÈóÆÈ¢òÊï∞Â≠¶ÂåñÔºåÂπ∂ÂèØ‰ª•Áî®Á≤æÁ°ÆÂú∞È£éÊ†ºÂàÜÊûêËøô‰∫õÈóÆÈ¢ò„ÄÇÊàëÁß∞Ëøô‰∫õ‰∫∫ÔºöÊúâÂàõÊÑèÁöÑÊï∞Â≠¶ÊÄùËÄÉËÄÖ„ÄÇ&lt;/p&gt;</content><author><name>Sida Liu</name></author><category term="Old" /><summary type="html">‰∏äÂçàËØª‰∫ÜKeith DevlinÊïôÊéàÁöÑËØæÁ®ãËÉåÊôØÊùêÊñôÔºåÊúâÁÇπÊÑüËß¶ÔºåÊëòÊäÑ‰∫ÜÂá†ÊÆµÂØπÊàëÂæàÊúâÂêØÂèëÁöÑÊñáÂ≠óÔºå‰ª•Â§áÊó•ÂêéÂèÇËÄÉ„ÄÇ</summary></entry></feed>