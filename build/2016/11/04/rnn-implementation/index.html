<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <title>Recurrent Neural Network(RNN) Implementation</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Recurrent Neural Network(RNN) Implementation" /> <meta name="keywords" content="Recurrent Neural Network(RNN) Implementation, Sida Liu, " /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Sida Liu" property="og:site_name"> <meta content="Recurrent Neural Network(RNN) Implementation" property="og:title"> <meta content="article" property="og:type"> <meta content="The world is so complex that we cannot stop learning." property="og:description"> <meta content="http://localhost:4000/2016/11/04/rnn-implementation/" property="og:url"> <meta content="2016-11-04T00:00:00-04:00" property="article:published_time"> <meta content="http://localhost:4000/about/" property="article:author"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="Recurrent Neural Network(RNN) Implementation"> <meta content="Sida Liu" property="og:site_name"> <meta name="twitter:url" content="http://localhost:4000/2016/11/04/rnn-implementation/"> <meta name="twitter:description" content="The world is so complex that we cannot stop learning."> <link rel="stylesheet" href="/assets/css/main.css" /> <!-- <link rel="stylesheet" href="/assets/css/custom-style.css" /> --> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.css" /> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.css"> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch-theme-algolia.min.css"> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <link rel="stylesheet" href="/assets/bower_components/icono/dist/icono.min.css"/> <!-- Fonts--> <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet"> <!-- Favicon --> <link rel="icon" href="http://localhost:4000/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha384-vk5WoKIaW/vJyUAd9n/wmopsmNhiy+L2Z+SBxGYnUkunIxVxAv/UtMOhba/xskxh" crossorigin="anonymous"></script> <!-- <script src="/assets/bower_components/jquery/dist/jquery.min.js"></script> --> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/picturefill/3.0.2/picturefill.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.20.1/moment.min.js"></script> <!-- Github Button --> <script async defer src="https://buttons.github.io/buttons.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script> </head><body> <nav class="navbar navbar-expand-lg fixed-top navbar-dark" id="topNav"> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation" > <span class="icono-hamburger" id="navbar-hamburger"> </span> </button> <a class="navbar-brand" href="/">Sida Liu</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="http://localhost:4000/about" >About Me</a > </li> <li class="nav-item"> <a class="nav-link" href="http://localhost:4000/blog" >Blog</a > </li> <li class="nav-item"> <a class="nav-link" href="http://localhost:4000/contact" >Contact Me</a > </li> </ul> </div> <ul class="nav justify-content-end"> <li class="nav-item"> <a class="nav-link" id="search-icon" href="http://localhost:4000/search#/" ><i class="fa fa-search" aria-hidden="true"></i ></a> </li> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() " type="checkbox" name="checkbox" /> </li> </ul> </nav> <div class="col-lg-12"> <div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <h1 class="post-title" itemprop="name headline">Recurrent Neural Network(RNN) Implementation</h1> <h4 class="post-meta"></h4> <p class="post-summary"> Posted by : at <time datetime="2016-11-04 00:00:00 -0400" itemprop="datePublished" >Nov 4, 2016</time > </p> <span class="disqus-comment-count" data-disqus-identifier="/2016/11/04/rnn-implementation/" ></span> <div class="post-categories"> Category : </div> </div> <div class="card-body" itemprop="articleBody"> <img class="card-img-top" src="http://localhost:4000/assets/img/posts/" alt="" /> <br /> <br /> <p>I heard about RNN for a long time, and have learned the concept several times, but until yesterday, I can’t implement any useful code to solve my own problem.</p> <p>So I checked some tutorial. The most basic one is applying RNN to the MNIST dataset. The sample code is from <a href="https://pythonprogramming.net/rnn-tensorflow-python-machine-learning-tutorial/">sentdex’s video tutorial</a>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">rnn</span><span class="p">,</span> <span class="n">rnn_cell</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s">"/tmp/data/"</span><span class="p">,</span> <span class="n">one_hot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">hm_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">n_chunks</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">128</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s">'float'</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_chunks</span><span class="p">,</span><span class="n">chunk_size</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s">'float'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">recurrent_neural_network</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="p">{</span><span class="s">'weights'</span><span class="p">:</span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">rnn_size</span><span class="p">,</span><span class="n">n_classes</span><span class="p">])),</span>
             <span class="s">'biases'</span><span class="p">:</span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_classes</span><span class="p">]))}</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_chunks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="p">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span><span class="n">state_is_tuple</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">lstm_cell</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">layer</span><span class="p">[</span><span class="s">'weights'</span><span class="p">])</span> <span class="o">+</span> <span class="n">layer</span><span class="p">[</span><span class="s">'biases'</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span> <span class="nf">train_neural_network</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">recurrent_neural_network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">AdamOptimizer</span><span class="p">().</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">initialize_all_variables</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hm_epochs</span><span class="p">):</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">mnist</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">num_examples</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)):</span>
                <span class="n">epoch_x</span><span class="p">,</span> <span class="n">epoch_y</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="n">epoch_x</span> <span class="o">=</span> <span class="n">epoch_x</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span><span class="n">n_chunks</span><span class="p">,</span><span class="n">chunk_size</span><span class="p">))</span>

                <span class="n">_</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">epoch_x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">epoch_y</span><span class="p">})</span>
                <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">c</span>

            <span class="k">print</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="s">'completed out of'</span><span class="p">,</span><span class="n">hm_epochs</span><span class="p">,</span><span class="s">'loss:'</span><span class="p">,</span><span class="n">epoch_loss</span><span class="p">)</span>

        <span class="n">correct</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="s">'float'</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Accuracy:'</span><span class="p">,</span><span class="n">accuracy</span><span class="p">.</span><span class="nb">eval</span><span class="p">({</span><span class="n">x</span><span class="p">:</span><span class="n">mnist</span><span class="p">.</span><span class="n">test</span><span class="p">.</span><span class="n">images</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_chunks</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)),</span> <span class="n">y</span><span class="p">:</span><span class="n">mnist</span><span class="p">.</span><span class="n">test</span><span class="p">.</span><span class="n">labels</span><span class="p">}))</span>

<span class="n">train_neural_network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p>I suggest you to watch <a href="https://pythonprogramming.net/rnn-tensorflow-python-machine-learning-tutorial/">sentdex’s video tutorial</a> first, and if you are not confident with what’s going on in the function <strong>recurrent_neural_network</strong>, you can go on read this article.</p> <p>Let’s take a close look at this function:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">recurrent_neural_network</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="p">{</span><span class="s">'weights'</span><span class="p">:</span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">rnn_size</span><span class="p">,</span><span class="n">n_classes</span><span class="p">])),</span>
             <span class="s">'biases'</span><span class="p">:</span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_classes</span><span class="p">]))}</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_chunks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="p">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span><span class="n">state_is_tuple</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">lstm_cell</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">layer</span><span class="p">[</span><span class="s">'weights'</span><span class="p">])</span> <span class="o">+</span> <span class="n">layer</span><span class="p">[</span><span class="s">'biases'</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div> <p>In the 1st line, we define variables for weights and biases. That’s common in any other neural network. If you don’t understand this line, you should go back and learn what is a neural network.</p> <p>Next, we make some tricks to the input X. Tensorflow cannot output the value right away, as it define the whole model first and run later, so we can use numpy to mimik this tricks to see what happened.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="c1">#First we define a small tensor to observe
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#Then do the transepose
</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">transpose</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#And do the reshape
</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#And do the split
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p>the outcome should be like this (I pretty the output a little):</p><pre><code class="language-code">[[[ 0  1  2]
  [ 3  4  5]
  [ 6  7  8]
  [ 9 10 11]]
 [[12 13 14]
  [15 16 17]
  [18 19 20]
  [21 22 23]]]

[[[ 0  1  2]
  [12 13 14]]
 [[ 3  4  5]
  [15 16 17]]
 [[ 6  7  8]
  [18 19 20]]
 [[ 9 10 11]
  [21 22 23]]]

[[ 0  1  2]
 [12 13 14]
 [ 3  4  5]
 [15 16 17]
 [ 6  7  8]
 [18 19 20]
 [ 9 10 11]
 [21 22 23]]

[array([[ 0,  1,  2],
       [12, 13, 14]]), array([[ 3,  4,  5],
       [15, 16, 17]]), array([[ 6,  7,  8],
       [18, 19, 20]]), array([[ 9, 10, 11],
       [21, 22, 23]])]
</code></pre><p>OK. We can see that, we finally have a list, which contains 4 elemnts. The 1st elements contains the 1st lines of the origin images. The 2nd contains the 2nd lines of origin images.</p> <p>Now the final list is the input of the RNN.</p> <p>After define a BasicLSTMCell cell, the next line is the key RNN implementation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">lstm_cell</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div> <p>Let take a look at <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py">the source code of rnn.rnn</a> on github, the programmer said that, the simplest form of RNN network generated is:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">state</span> <span class="o">=</span> <span class="n">cell</span><span class="p">.</span><span class="n">zero_state</span><span class="p">(...)</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">input_</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">cell</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">outputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</code></pre></div></div> <p>That’s good! The output is also a list, just like the input list.</p> <p><img src="/images/rnn_flow.png" alt="RNN-flow" /></p> <p>Every single LSTM cell has a layer, which contain 128(rnn_size) neurals. At first, we feed the LSTM cell with the first slide of our input list, which is happen to be the whole first origin image. The first line of first origin image goes to the first LSTM first. Because the rnn has 128(rnn_size) neurals, so it will output 128 numbers this time. And then the 2nd line of first origin image goes to the 2nd LSTM, until meets the final line, and get another 128 numbers output… Finally, we will input all images in this batch, and get a batch of result.</p> <p>And it comes to the final line:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">layer</span><span class="p">[</span><span class="s">'weights'</span><span class="p">])</span> <span class="o">+</span> <span class="n">layer</span><span class="p">[</span><span class="s">'biases'</span><span class="p">]</span>
</code></pre></div></div> <p>We see that only the last element of output is used. Sometimes we use all of the outputs list, and sometimes we just use the last one. That is because the information is contained in the last output. Why? Because this cell is called Long-short Term Memory(LSTM). It is designed to remember the whole sequence!</p> <p>Here is a very good tutoral of <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">What is LSTM</a>.</p> <p>Thank you for reading. Comments are welcomed.</p> </div><!-- Incomment incase you want to use Disqus <div id="disqus_thread"></div> --> </article> <script> var disqus_config = function () { this.page.url = "http://localhost:4000/2016/11/04/rnn-implementation/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/2016/11/04/rnn-implementation"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header">About Sida Liu</div> <div class="card-body"> <p class="author_bio">I am currently a M.S. graduate student of Complex Systems Center in University of Vermont. I am interested in artificial intelligence, artificial life, and artificial environment.</p><!-- Place this tag where you want the button to render. --> <a class="github-button" href="https://github.com/liusida" data-size="large" data-show-count="true" aria-label="Follow @liusida on GitHub">Follow @liusida</a></div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories</div> <div class="card-body text-dark"> <div id="#Thoughts"></div> <li class="tag-head"> <a href="/blog/categories/Thoughts">Thoughts</a> </li> <a name="Thoughts"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links</div> <div class="card-body text-dark"> <li> <a href="http://localhost:4000/about">About Me</a> </li> <li> <a href="http://localhost:4000/blog">Blog</a> </li> <li> <a href="http://localhost:4000/contact">Contact Me</a> </li> </div> </div> </div> </div> </div><footer> <p> Powered by <strong>devlopr jekyll</strong>. Subscribe via <a href=" /feed.xml ">RSS</a> </p> </footer> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> <script src="/assets/js/mode-switcher.js"></script> </body> </html>
